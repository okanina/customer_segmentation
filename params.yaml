train_test_split_ratio: 0.2

models:
  DecisionTreeClassifier:
    criterion: [gini, entropy]
    splitter: [best]
    max_depth: [10, 20, 30]   
    random_state: [42]

  LogisticRegression:
    max_iter: [500, 1000]
    solver: [lbfgs, saga]
    warm_start: [False]
    random_state: [42]

  RandomForestClassifier:
    n_estimators: [50, 100]
    bootstrap: [True, False]
    max_depth: [10, 20, 30] 
    max_features: [sqrt, log2]
    criterion: [gini, entropy]    
    random_state: [42]
    warm_start: [False]

XGBClassifier:
  max_depth: [6, 9, 12]